# ----------------------------------------------------------------------
# LALSuite: Gitlab-CI configuration
#
# If you have any questions, please email lal-discuss@ligo.org, or open
# a question ticket at https://git.ligo.org/lscsoft/lalsuite/-/issues/
# ----------------------------------------------------------------------

# -- setup --------------------------------------

stages:
  # make tarballs for each subpackage
  - tarballs
  # build packages for each subpackage
  - LAL
  - LALFrame
  - LALMetaIO
  - LALSimulation
  - LALBurst
  - LALInspiral
  - LALInference
  - LALPulsar
  - LALApps
  - wheels
  # end-to-end tests
  - integration tests
  - compiler tests
  - platform tests
  - upgrade tests
  # build containers
  - docker
  # quality checks
  - coverage
  - lint
  # documentation
  - documentation
  # deploy packages
  - deploy

include:
  # include job templates from the gitlab-ci-templates repo
  # see https://computing.docs.ligo.org/gitlab-ci-templates/
  - project: computing/gitlab-ci-templates
    file:
      # helpers for debian builds
      - debian.yml
      # helpers for RHEL builds
      - rhel.yml
      # a flake8 job template
      - python.yml

  # retry() macro
  - local: '/.gitlab/ci/retry.yml'

  # CI rules
  - local: '/.gitlab/ci/rules.yml'

  # make tarballs for each subpackage
  - local: '/.gitlab/ci/tarballs.yml'

  # build packages for each subpackage
  - local: '/.gitlab/ci/conda.yml'
  - local: '/.gitlab/ci/deb.yml'
  - local: '/.gitlab/ci/pkg.yml'
  - local: '/.gitlab/ci/rpm.yml'
  - local: '/.gitlab/ci/wheels.yml'

  # end-to-end tests
  - local: '/.gitlab/ci/integration.yml'
  - local: '/.gitlab/ci/compilers.yml'
  - local: '/.gitlab/ci/platform.yml'
  - local: '/.gitlab/ci/upgrade.yml'

  # build containers
  - local: '/.gitlab/ci/containers.yml'

  # quality checks
  - local: '/.gitlab/ci/coverage.yml'
  - local: '/.gitlab/ci/lint.yml'

  # documentation
  - local: '/.gitlab/ci/docs.yml'

  # deploy packages
  # - wheels: see .gitlab/ci/wheels.yml

# -- global settings ----------------------------

# by default cache everything in the .cache directory
cache:
  key: "${CI_JOB_NAME}"
  paths:
    - .cache

variables:
  PIPELINE_NAME: "LALSuite CI/CD"

  # job stage attempts
  ARTIFACT_DOWNLOAD_ATTEMPTS: 2
  EXECUTOR_JOB_SECTION_ATTEMPTS: 2
  GET_SOURCES_ATTEMPTS: 2
  RESTORE_CACHE_ATTEMPTS: 2

  # run autoreconf in pedantic and loud mode
  AUTORECONF: "autoreconf --verbose --warnings=error"

  # version of python to use for builds
  LALSUITE_PYTHON_VERSION: "3.12"

  # gitlab runners have 4 cores per job
  CPU_COUNT: 4

  # don't need git history
  GIT_DEPTH: 1

  # global build helpers
  VERBOSE: "true"

  # where to store files, ideally everything that is 'cache'
  # should go under ${CI_PROJECT_DIR}/.cache to match the
  # cache key setting above
  XDG_CONFIG_HOME: "${CI_PROJECT_DIR}/.config"
  XDG_CACHE_HOME: "${CI_PROJECT_DIR}/.cache"
  CCACHE_DIR: "${CI_PROJECT_DIR}/.cache/ccache"
  CONDA_PKGS_DIRS: "${CI_PROJECT_DIR}/.cache/conda/pkgs"
  PIP_CACHE_DIR: "${CI_PROJECT_DIR}/.cache/pipe"

  # where to build conda environments (i.e. not in ~/.conda)
  CONDA_ENVS_PATH: "${CI_PROJECT_DIR}/envs"

  # what file to use for conda configuration
  CONDARC: "${CI_PROJECT_DIR}/.condarc"

  # tell Debian-based installers to run non-interactively
  DEBIAN_FRONTEND: noninteractive

  # canonical list of LALSuite packages
  LALSUITE_PACKAGES: >-
    lal
    lalframe lalmetaio lalsimulation
    lalburst lalinspiral lalinference lalpulsar
    lalapps

# default parameters for jobs
default:
  # retry running jobs on abnormal failures
  retry:
    max: 2
    when:
      - unknown_failure
      - stuck_or_timeout_failure
      - runner_system_failure
      - stale_schedule
      - archived_failure
      - scheduler_failure
    exit_codes:
      # exit code of retry() macro after all attempts
      - 111

  # cancel job when a newer pipeline starts
  interruptible: true

# -- helper fragments ----------------------------------

# to use:
# - !reference [.name-of-fragment]

# basic steps for a job that compiles stuff
.build-init:
  # use retry()
  - !reference [.retry]
  # do not save coredumps
  - ulimit -S -c 0
  # set up ccache
  - export PATH=/usr/lib/ccache:/opt/local/libexec/ccache:$PATH
  # print environment for debugging
  - |
    echo "===== env ====="
    declare -x | cut -c 12-
    echo "----- env -----"
  # ensure Git-LFS files are checked out
  - |
    test "X${GIT_STRATEGY}" = Xnone || ( git lfs ls-files | sed 's/^/LFS: /' )

# set up Python virtual environment for pip installing local packages, etc.
.python-venv:
  - !reference [.retry]
  - |
    rm -rf .venv/
    ${PYTHON:-python3} -m venv --system-site-packages .venv/
    source .venv/bin/activate
    for n in python python3 pip; do
      if [ "X`type -p ${n}`" != "X${VIRTUAL_ENV}/bin/${n}" ]; then
         echo "ERROR: virtual environment in '${VIRTUAL_ENV}' is missing ${n}" >&2
         exit 1
      fi
    done
    retry python -m pip install --upgrade pip

# concatenate code quality reports
# - concatenate all reports matching `code-quality-*.json` into a single report
# - mark non-ignored entries as "blocker", requiring them to be addressed
# - returns non-zero exit code if there are any non-ignored entries
.concatenate-code-quality:
  - |
    python <<EOF
    import json
    import os
    import re
    import sys
    from pathlib import Path
    ignore_severity_regex = r''
    concat_code_qual = []
    exit_code = 0
    wd = Path(os.environ["CI_PROJECT_DIR"])
    for fn in wd.glob("code-quality-*.json"):
      severities = {}
      with fn.open("rt") as f:
        code_qual = json.load(f)
      for cq in code_qual:
        if re.fullmatch(ignore_severity_regex, cq["severity"]) is None:
          cq["severity"] = "blocker"
          exit_code = 1
        concat_code_qual.append(cq)
        sv = severities.get(cq["severity"], 0)
        severities[cq["severity"]] = sv + 1
      print(f"Found code quality report: {fn}", end="")
      if severities:
        for severity, count in sorted(severities.items()):
          if re.fullmatch(ignore_severity_regex, severity) is None:
            severity = severity.upper()
          print(f", {severity}={count}", end="")
      n = len(code_qual)
      print(f", total={n} entries")
    concat_fn = wd / "code-quality.json"
    with concat_fn.open("wt") as f:
      json.dump(concat_code_qual, f)
    print(f"Concatenated code quality report: {concat_fn}")
    sys.exit(exit_code)
    EOF

# -- base templates ----------------------------------

# basic before_script template for a compiling job
.build-job:
  timeout: 3 hours
  before_script:
    - !reference [.build-init]

# helper template for jobs running on macOS
.macos-job:
  variables:
    # use the clone strategy so permissions are correctly reset on any failed jobs
    # see: https://gitlab.com/gitlab-org/gitlab-runner/-/merge_requests/3726
    GIT_STRATEGY: clone
    # Clang has weird bugs when compiling with CFLAGS=-O3
    CFLAGS: "-O2"
    # stop Clang generating profile files
    LLVM_PROFILE_FILE: "/dev/null"

# tag for macOS x86_64 architecture jobs
.macos-x86_64:
  extends:
    - .macos-job
  tags:
    - macos_x86_64

# tag for macOS arm64 architecture jobs
.macos-arm64:
  extends:
    - .macos-job
  tags:
    - macos_arm64

# deploy outputs to various locations
.deploy:
  stage: deploy
  variables:
    GIT_STRATEGY: none
  retry: 0
  interruptible: false

# -- CI job templates ----------------------------------

# a top-level build runs the standard boot/configure/make
# cycle with some sensible defaults
.make-distcheck:
  extends:
    - .build-job
  variables:
    # default configure flags (can be overridden from dependents)
    CONFIGURE_FLAGS: "--enable-doxygen --enable-python --enable-swig-python"
    # default C flags (can be overridden from dependents)
    CFLAGS: "-O3"
    # target to actually run (distcheck is the most thorough)
    MAKE_TARGET: "distcheck"
  needs: []
  script:
    - ./00boot
    # we use xargs here in case CONFIGURE_FLAGS contains
    # variables with spaces, etc etc
    - xargs ./configure
          --enable-strict-defs
          ${ENABLE_NIGHTLY}
          CFLAGS="${CFLAGS}"
          LALSUITE_LIBTOOL_NO_SUPPRESS=1
          <<< ${CONFIGURE_FLAGS}
    # install build dependencies, if requested
    - |
      if test "X$(declare -F install_build_deps)" != X; then
        echo "Installing build dependencies ..."
        install_build_deps
      else
        echo "Not installing build dependencies"
      fi
    # build
    - make -j${CPU_COUNT} VERBOSE=1 ${MAKE_TARGET:-distcheck}
  artifacts:
    # upload some files to debug failures
    paths:
      - config.log
      - Makefile
      - lal*/config.log
      - lal*/libtool
      - lal*/Makefile
      - lal*/**/test-suite.log
    when: on_failure

# install deb dependencies for top-level builds
.make-distcheck-deb:
  extends:
    - .make-distcheck
  before_script:
    - !reference [.make-distcheck, before_script]
    - |
      install_build_deps() {
        retry apt-get update -y -q
        local subdir
        for subdir in ${LALSUITE_PACKAGES}; do
          if test -f ${subdir}/config.log; then
            pushd ${subdir}
            awk '
              /^Build-Depends:/ { bd=1; print; next }
              bd==1 && ( / lal/ || / liblal/ || / python.*-lal/ ) { next }
              /^[^ ]/ { bd=0 }
              { print }
            ' debian/control > debian/control.tmp
            mv -f debian/control.tmp debian/control
            retry apt-get build-dep -y -q .
            popd
          fi
        done
      }

# install rpm dependencies for top-level builds
.make-distcheck-rpm:
  extends:
    - .make-distcheck
  before_script:
    - !reference [.make-distcheck, before_script]
    - |
      install_build_deps() {
        local specs
        local subdir
        for subdir in ${LALSUITE_PACKAGES}; do
          if test -f ${subdir}/config.log; then
            local spec="${subdir}/${subdir}.spec"
            sed -i -e '/BuildRequires: *\(lal\|liblal\|python.*-lal\)/d' ${spec}
            specs="${specs} ${spec}"
          fi
        done
        retry yum-builddep -y -q ${specs}
      }
