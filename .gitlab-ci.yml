# ----------------------------------------------------------------------
# LALSuite: Gitlab-CI configuration
#
# This file is complicated, but hopefully robust. If you have any
# questions, please email lal-discuss@ligo.org, or open a question
# ticket at https://git.ligo.org/lscsoft/lalsuite/-/issues/
# ----------------------------------------------------------------------

# -- setup --------------------------------------

stages:
  - tarballs
  # build packages for each subpackage
  - LAL
  - LALFrame
  - LALMetaIO
  - LALSimulation
  - LALBurst
  - LALInspiral
  - LALInference
  - LALPulsar
  - LALApps
  - wheels
  # end-to-end tests
  - integration tests
  - compiler tests
  - platform tests
  - upgrade tests
  # build containers
  - docker
  # quality checks
  - coverage
  - lint
  # documentation
  - documentation
  # deploy packages
  - deploy

include:
  # include job templates from the gitlab-ci-templates repo
  # see https://computing.docs.ligo.org/gitlab-ci-templates/
  - project: computing/gitlab-ci-templates
    file:
      # helpers for codequality jobs
      - codequality.yml
      # helpers for debian builds
      - debian.yml
      # helpers for RHEL builds
      - rhel.yml
      # a flake8 job template
      - python.yml

  # CI rules
  - local: '/.gitlab/ci/rules.yml'

  # build packages for each subpackage
  - local: '/.gitlab/ci/deb.yml'
  - local: '/.gitlab/ci/pkg.yml'
  - local: '/.gitlab/ci/rpm.yml'
  - local: '/.gitlab/ci/wheels.yml'

  # end-to-end tests
  - local: '/.gitlab/ci/integration.yml'
  - local: '/.gitlab/ci/compilers.yml'
  - local: '/.gitlab/ci/platform.yml'
  - local: '/.gitlab/ci/upgrade.yml'

  # build containers
  - local: '/.gitlab/ci/containers.yml'

  # quality checks
  - local: '/.gitlab/ci/coverage.yml'
  - local: '/.gitlab/ci/lint.yml'

  # documentation
  - local: '/.gitlab/ci/docs.yml'

  # deploy packages
  # - wheels: see .gitlab/ci/wheels.yml

# -- global settings ----------------------------

# by default cache everything in the .cache directory
cache:
  key: "${CI_JOB_NAME}"
  paths:
    - .cache

variables:
  PIPELINE_NAME: "LALSuite CI/CD"
  # run autoreconf in pedantic and loud mode
  AUTORECONF: "autoreconf --verbose --warnings=error"
  # version of python to use for builds
  LALSUITE_PYTHON_VERSION: "3.10"
  # gitlab runners have 4 cores per job
  CPU_COUNT: 4
  # don't need git history
  GIT_DEPTH: 1
  # global build helpers
  VERBOSE: "true"
  # where to store files, ideally everything that is 'cache'
  # should go under ${CI_PROJECT_DIR}/.cache to match the
  # cache key setting above
  XDG_CONFIG_HOME: "${CI_PROJECT_DIR}/.config"
  XDG_CACHE_HOME: "${CI_PROJECT_DIR}/.cache"
  CCACHE_DIR: "${CI_PROJECT_DIR}/.cache/ccache"
  CONDA_PKGS_DIRS: "${CI_PROJECT_DIR}/.cache/conda/pkgs"
  PIP_CACHE_DIR: "${CI_PROJECT_DIR}/.cache/pipe"
  # where to build conda environments (i.e. not in ~/.conda)
  CONDA_ENVS_PATH: "${CI_PROJECT_DIR}/envs"
  # what file to use for conda configuration
  CONDARC: "${CI_PROJECT_DIR}/.condarc"
  # tell Debian-based installers to run non-interactively
  DEBIAN_FRONTEND: noninteractive

# default parameters for jobs
default:
  # retry running jobs on failure
  retry: 1
  # cancel job when a newer pipeline starts
  interruptible: true

# -- templates ----------------------------------

.print-env: &print-env
  echo "===== env ====="; env; echo "----- env -----"

.configure-ccache: &configure-ccache
  export PATH=/usr/lib/ccache:/opt/local/libexec/ccache:$PATH

.configure-coredump: &configure-coredump
  ulimit -S -c 0

# basic steps for a job that compiles stuff
# can be included in the before_script/script sections
# via `*init-build-job`
.build-init: &init-build-job
  - *print-env
  - *configure-ccache
  - *configure-coredump

# simple bash command to retry a stage up to 3 times
# with a 15-second delay (mainly to survive transient
# network issues)
.retry: &define-retry |
  retry() {
    local n=1
    local max=3
    local delay=15
    while true; do
      "$@" && break || {
        if [[ $n -lt $max ]]; then
          ((n++))
          echo "Command failed. Attempt $n/$max:"
          sleep $delay;
        else
          echo "The command has failed after $n attempts." 1>&2
          exit 1
        fi
    }
    done
  }

# basic before_script template for a compiling job
.build-job:
  timeout: 3 hours
  before_script:
    - *init-build-job

# a top-level build runs the standard boot/configure/make
# cycle with some sensible defaults
.make-distcheck:
  extends:
    - .build-job
  variables:
    # default configure flags (can be overridden from dependents)
    CONFIGURE_FLAGS: "--enable-doxygen --enable-python --enable-swig-python"
    # default C flags (can be overridden from dependents)
    CFLAGS: "-O3"
    # target to actually run (distcheck is the most thorough)
    MAKE_TARGET: "distcheck"
    # set default python as python3
    # TODO: this can be removed when all packages require python>=3
    #       on their own
    PYTHON: "python3"
  needs: []
  script:
    - ./00boot
    # we use xargs here in case CONFIGURE_FLAGS contains
    # variables with spaces, etc etc
    - xargs ./configure
          --enable-strict-defs
          ${ENABLE_NIGHTLY}
          CFLAGS="${CFLAGS}"
          LALSUITE_LIBTOOL_NO_SUPPRESS=1
          <<< ${CONFIGURE_FLAGS}
    - make -j${CPU_COUNT} VERBOSE=1 ${MAKE_TARGET:-distcheck}
  artifacts:
    # upload some files to debug failures
    paths:
      - config.log
      - Makefile
      - lal*/config.log
      - lal*/libtool
      - lal*/Makefile
      - lal*/**/test-suite.log
    when: on_failure

# helper template for jobs running on macOS
.macos-job:
  variables:
    # use the clone strategy so permissions are correctly reset on any failed jobs
    # see: https://gitlab.com/gitlab-org/gitlab-runner/-/merge_requests/3726
    GIT_STRATEGY: clone
    # Clang has weird bugs when compiling with CFLAGS=-O3
    CFLAGS: "-O2"

# tag for macOS x86_64 architecture jobs
.macos:
  extends:
    - .macos-job
  tags:
    - macos_x86_64

# tag for macOS arm64 architecture jobs
.macos-arm64:
  extends:
    - .macos-job
  tags:
    - macos_arm64

# -- build templates ----------------------------

# jobs that build from the tarballs should not need
# the git repository (this speeds things up and prevents
# other issues)
.build-from-tarball:
  variables:
    GIT_STRATEGY: none

# -- conda

# initialise conda for 'conda build jobs'
# note: this assumes that the base environment is writable,
#       which is not the case by default for the shared
#       macos runners at CIT, if you need a writable base env
#       on those machines, install miniconda/miniforge yourself
.conda-init: &conda-init
  - *define-retry
  # init conda
  - mkdir -p $(dirname ${CONDA_PKGS_DIRS})
  - source ${CONDA_ROOT:=/opt/conda}/etc/profile.d/conda.sh
  # configure conda options
  - rm -fv ${CONDARC}  # start afresh
  - conda config --file ${CONDARC} --set always_yes yes
  - conda config --file ${CONDARC} --add channels conda-forge
  - conda config --file ${CONDARC} --set channel_priority strict
  # see https://github.com/conda-forge/conda-forge-ci-setup-feedstock/pull/168
  - conda config --show aggressive_update_packages >> ${CONDARC}
  - conda config --file ${CONDARC} --remove aggressive_update_packages openssl
  # install build helpers
  - retry conda install -n base
        "conda-build!=3.18.10"
        conda-forge-pinning
        "conda-smithy>=3.7.5"
        conda-libmamba-solver
        conda-verify
  # print info
  - conda activate base
  - conda info --all
  - conda config --show-sources
  - conda config --show
  - conda list --name base

# template for jobs that use conda (in any context)
.conda-job:
  image: igwn/base:conda
  variables:
    # where to write conda packages
    CONDA_BLD_PATH: "${CI_PROJECT_DIR}/conda-bld"
    # dont clone the git repo
    GIT_STRATEGY: none
  before_script:
    - *init-build-job
    - *define-retry
    - *conda-init

# template for `conda build` jobs
.conda-build:
  extends:
    - .conda-job
  variables:
    # stub of feedstock configuration file
    CONDA_CONFIG: "linux_64_"
    # get verbose logging from conda smithy
    CONDA_SMITHY_LOGLEVEL: "DEBUG"
  script:
    - PACKAGE=${CI_JOB_NAME%%:*}
    - cd ${PACKAGE}/
    # copy local packages from conda-bld dir to a new channel
    - if [ -d "${CONDA_BLD_PATH}" ]; then
          LOCAL_CHANNEL="${CI_PROJECT_DIR}/local-builds";
          rm -rf "${LOCAL_CHANNEL}";
          cp -rv "${CONDA_BLD_PATH}" "${LOCAL_CHANNEL}";
          conda index "${LOCAL_CHANNEL}";
          conda config --file ${CONDARC} --add channels "${LOCAL_CHANNEL}";
          conda search "*lal*" --channel "${LOCAL_CHANNEL}" --override-channels;
          rm -rf "${CONDA_BLD_PATH}";
      fi
    # render YAML file to use our tarball
    - TARBALL=$(ls -t1 ${PACKAGE}-*.tar.* | head -n1 | xargs readlink -f)
    - SHA256=$(openssl dgst -r -sha256 $TARBALL | cut -d\  -f1)
    - tar -xf ${TARBALL} --wildcards ${PACKAGE}-*/conda/ --strip-components=1
    - sed 's|@TARBALL@|'${TARBALL}'|g' conda/meta.yaml.in > conda/meta.yaml
    - sed -i 's|@SHA256@|'${SHA256}'|g' conda/meta.yaml
    # create a feedstock from the conda recipe
    - git config --global user.name "${GITLAB_USER_NAME}"
    - git config --global user.email "${GITLAB_USER_EMAIL}"
    - conda smithy init conda/ --feedstock-directory ${PACKAGE}-feedstock
    - cd ${PACKAGE}-feedstock
    # handle migrations that are bundled with the tarball
    - mkdir -p .ci_support/migrations
    - find recipe/migrations -type f -name "*.yaml" -exec cp -n -v {} .ci_support/migrations/ \;
    # regenerate the feedstock
    - retry conda smithy regenerate --no-check-uptodate
    - git ls-files
    # configure CONDA_CONFIG
    - _CONDA_CONFIG_PYTHON_REGEX="(.*python)${LALSUITE_PYTHON_VERSION}(.*)"
    - |
      # if this is a nightly build and CONDA_CONFIG refers to a single python
      # version, expand it to include all Python versions in the feedstock
      if [ ! -z "${ENABLE_NIGHTLY}" ] && [[ "${CONDA_CONFIG}" =~ ${_CONDA_CONFIG_PYTHON_REGEX} ]]; then
        CONDA_CONFIG=$(basename -s .yaml .ci_support/${BASH_REMATCH[1]}*${BASH_REMATCH[2]}.yaml);
      # otherwise if this is NOT a nightly build and CONDA_CONFIG doesn't
      # refer to a single python version, specify `--python` to build only
      # the reference Python version
      elif [ -z "${ENABLE_NIGHTLY}" ] && [[ ! "${CONDA_CONFIG}" =~ ${_CONDA_CONFIG_PYTHON_REGEX} ]]; then
        CONDA_BUILD_ARGS="--python \"${LALSUITE_PYTHON_VERSION}.* *_cpython\"";
      fi
    # ensure $CI_COMMIT_TAG is set for script_env
    - export CI_COMMIT_TAG=${CI_COMMIT_TAG:-}
    # build packages
    # NOTE: we use xargs here because CONDA_BUILD_ARGS contains multiple spaces
    # NOTE: retry if conda build fails due to corrupted $CONDA_PKGS_DIRS
    - |
      # loop over chosen configurations
      for _CONDA_CONFIG in ${CONDA_CONFIG}; do
      # loop over retry
      for n in 1 2; do
        echo "===== conda build: attempt $n of 2 ====="
        if ( \
          set -o pipefail; \
          xargs -t conda build \
            recipe/ \
            --dirty \
            --error-overlinking \
            --keep-old-work \
            --no-anaconda-upload \
            --variant-config-files .ci_support/${_CONDA_CONFIG}.yaml \
            <<< ${CONDA_BUILD_ARGS} \
          2>&1 | awk '{print} /appears to be corrupted/ {exit 1}' \
        ); then
          echo "----- conda build: success -----"
          break
        else
          echo "... output from conda build truncated"
          if [ $n -eq 1 ] && [ "X${CONDA_PKGS_DIRS}" != X ]; then
            echo "----- conda build: possibly ${CONDA_PKGS_DIRS} is corrupted, deleting and retrying -----"
            rm -rf ${CONDA_PKGS_DIRS}
          else
            echo "----- conda build: something else is corrupted, failing -----"
            exit 1
          fi
        fi
      done  # retry
      done  # configs
  after_script:
    # clean cache of old files
    - find ${CONDA_PKGS_DIRS%:*} -atime +30 -delete
    - find ${CONDA_PKGS_DIRS%:*} -type d -empty -delete
  artifacts:
    expire_in: 18h
    paths:
      # built packages (matching this package only)
      - "conda-bld/**/${CI_JOB_NAME%%:*}-*.conda"
      - "conda-bld/**/${CI_JOB_NAME%%:*}-*.tar.bz2"
      - "conda-bld/**/lib${CI_JOB_NAME%%:*}-*.conda"
      - "conda-bld/**/lib${CI_JOB_NAME%%:*}-*.tar.bz2"
      - "conda-bld/**/python-${CI_JOB_NAME%%:*}-*.conda"
      - "conda-bld/**/python-${CI_JOB_NAME%%:*}-*.tar.bz2"
      # log files
      - "conda-bld/${CI_JOB_NAME%%:*}-*/work/**/config.log"
      - "conda-bld/${CI_JOB_NAME%%:*}-*/work/**/test-suite.log"
      # generated sources
      - "conda-bld/${CI_JOB_NAME%%:*}-*/work/**/swiglal_lal*_octave.cpp"
      - "conda-bld/${CI_JOB_NAME%%:*}-*/work/**/swiglal_lal*_python.c"
      # the feedstock
      - "${CI_JOB_NAME%%:*}/${CI_JOB_NAME%%:*}-feedstock/"
    reports:
      # conda-build deletes the _test_tmp directory for each
      # package, so we write them into the project directory
      junit: "*junit*.xml"
    when: always
  rules:
    - !reference [.ci-conda, rules]
    - !reference [.ci-merge-build, rules]
    - !reference [.ci-nightly-deploy, rules]

# -- tarballs -----------------------------------
#
# make tarballs for each subpackage
#

# job template for a subpackage tarball build;
# to build a tarball for a subpackage just define
# a job called `tarball:<subpackage>` that
# `extends` this one (see `tarball:lal` below)
.make-dist:
  image: igwn/lalsuite-dev:bookworm
  stage: tarballs
  needs: []
  extends:
    - .build-job
  script:
    - pushd ${CI_JOB_NAME##*:}
    - ./00boot
    - ./configure ${ENABLE_NIGHTLY}
    - make dist
  artifacts:
    expire_in: 18h
    # store the tarballs
    paths:
      - "*/*.tar.*"
    # there are no reports for tarball jobs
    reports:
      junit: []

# make tarballs for _all_ packages
tarballs:
  extends:
    - .make-dist
  script:
    - ./00boot
    - ./configure ${ENABLE_NIGHTLY}
    - for subdir in lal lalframe lalmetaio lalsimulation lalburst lalinspiral lalinference lalpulsar lalapps; do
        pushd ${subdir};
        make dist;
        popd;
      done

# make the tarball for LAL only
# (this job will run much faster than the `tarballs` job
#  so we use it to release the 'LAL' stage jobs as
#  early as possible)
tarball:lal:
  extends:
    - .make-dist

# -- lal ----------------------------------------
#
# build packages for LAL
#

.lal:
  stage: LAL
  needs:
    - tarball:lal

# build with conda using FFTW
lal:conda:fftw:
  extends:
    - .conda-build
    - .lal
  variables:
    CONDA_CONFIG: "linux_64_fft_implfftw"

# build with conda using Intel FFT (MKL)
lal:conda:mkl:
  extends:
    - .conda-build
    - .lal
  variables:
    CONDA_CONFIG: "linux_64_fft_implmkl"

# -- lalframe------------------------------------
#
# build packages for LALFrame
#

.lalframe:
  stage: LALFrame

lalframe:conda:
  extends:
    - .conda-build
    - .lalframe
  needs:
    - tarballs
    - lal:conda:fftw

# -- lalmetaio ----------------------------------
#
# build packages for LALMetaIO
#

.lalmetaio:
  stage: LALMetaIO

lalmetaio:conda:
  extends:
    - .conda-build
    - .lalmetaio
  needs:
    - tarballs
    - lal:conda:fftw

# -- lalsimulation ------------------------------
#
# build packages for LALSimulation
#

.lalsimulation:
  stage: LALSimulation

lalsimulation:conda:
  extends:
    - .conda-build
    - .lalsimulation
  needs:
    - tarballs
    - lal:conda:fftw
  variables:
    CONDA_CONFIG: "linux_64_*python${LALSUITE_PYTHON_VERSION}.*cpython"

# -- lalburst -----------------------------------
#
# build packages for LALBurst
#

.lalburst:
  stage: LALBurst

lalburst:conda:
  extends:
    - .conda-build
    - .lalburst
  needs:
    - tarballs
    - lal:conda:fftw
    - lalmetaio:conda
    - lalsimulation:conda

# -- lalinspiral --------------------------------
#
# build packages for LALInspiral
#

.lalinspiral:
  stage: LALInspiral

lalinspiral:conda:
  extends:
    - .conda-build
    - .lalinspiral
  needs:
    - tarballs
    - lal:conda:fftw
    - lalframe:conda
    - lalmetaio:conda
    - lalsimulation:conda
    - lalburst:conda

# -- lalinference -------------------------------
#
# build packages for LALInference
#

.lalinference:
  stage: LALInference

lalinference:conda:
  extends:
    - .conda-build
    - .lalinference
  needs:
    - tarballs
    - lal:conda:fftw
    - lalframe:conda
    - lalmetaio:conda
    - lalsimulation:conda
    - lalburst:conda
    - lalinspiral:conda

# -- lalpulsar ----------------------------------
#
# build packages for LALPulsar
#

.lalpulsar:
  stage: LALPulsar

lalpulsar:conda:
  extends:
    - .conda-build
    - .lalpulsar
  needs:
    - tarballs
    - lal:conda:fftw
    - lalframe:conda
    - lalmetaio:conda
    - lalsimulation:conda
    - lalburst:conda
    - lalinspiral:conda
    - lalinference:conda

# -- lalapps ------------------------------------
#
# build packages for LALApps
#

.lalapps:
  stage: LALApps

lalapps:conda:
  extends:
    - .conda-build
    - .lalapps
  needs:
    - tarballs
    - lal:conda:fftw
    - lalframe:conda
    - lalmetaio:conda
    - lalsimulation:conda
    - lalburst:conda
    - lalinspiral:conda
    - lalinference:conda
    - lalpulsar:conda
  variables:
    CONDA_CONFIG: "linux_64_*python${LALSUITE_PYTHON_VERSION}.*cpython"

# -- deploy -------------------------------------
#
# Deploy outputs to various locations
#

.deploy:
  stage: deploy
  variables:
    GIT_STRATEGY: none
  retry: 0
  interruptible: false
