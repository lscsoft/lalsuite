% $Id$

\section{Running the LALApps Stochastic Pipeline Under Condor}

This section describes how to run the LALApps stochastic analysis
pipeline under Condor at the various LSC Data Grid Sites, such as CIT,
UWM, and the observatory clusters at LHO and LLO.

The pipeline is constructed as a directed acyclic graph (DAG) run under
Condor. A DAG represents a set of programs where the input, output, or
execution of one ore more programs is dependant upon one or more other
programs. The programs are represented by nodes (verticies) in the
graph, and the edges (arcs) identifies the dependancies. There are three
different nodes that make up the Stochastic analysis DAG - datafind,
stochastic and stopp. A short description of the nodes that make up the
stochastic DAG follows:

\subsubsection{Datafind Node}

The datafind node, as its name suggests, is for determining the location
of the data that is to be analysed. It uses \texttt{LSCdataFind} to
query the LDR database for the location of the data on the cluster. This
step in the pipeline does not need to be run for analysis, only when the
location of the data changes.

\subsubsection{Stochastic Node}

The stochastic node runs an instance of \prog{lalapps\_stochastic}, the
main stochastic analysis code. See
Section~\ref{program:lalapps-stochastic} for more information on
\prog{lalapps\_stochastic}.

\subsubsection{Stopp Node}

The stopp node runs an instance of \prog{lalapps\_stopp}, the STOchastic
Post Processing code. See Section~\ref{program:lalapps-stopp} for more
information on \prog{lalapps\_stopp}.

\subsection{Creating the DAG}

In order to create the DAG, a configuration file is required, an example
of which can be found in\\
\texttt{\$LALAPPS\_PREFIX\$/share/lalapps/stochastic\_S3\_H1L1.ini}.
This configuration specfies the parameters to use for each step of the
pipeline. See Section~\ref{program:lalapps-stochastic-pipe} for details
regarding the layout of the configuration file.

Any combination of nodes, see above, can be present in the DAG, assuming
that the dependancies for each node are satisfied. The datafine node has
no dependancies, the stochastic node requires cache files to be
available, so if cache have already been generated and the location of
the data on the cluster has not changed then there is no read for the
datafind node to be run, and finally the stopp node requires that the
xml output file from \prog{lalapps\_stochastic} are available.

The following example will create a DAG containing all nodes, datafind,
stochastic and stopp.

\begin{verbatim}
> lalapps_stochastic_pipe --datafind --stochastic --stopp \
    --config-file example_S3_H1L1.ini --log-path logs
\end{verbatim}

In addition to creating the DAG it will also create several other file
required for running the search under condor, descriptions of these
files can be found below,

\begin{description}
\item[\texttt{example\_S3\_H1L1.dag}]
This is main dag file that includes all the required information for
running the pipeline. This includes the dependancy information for each
job within the DAG along with all the dynamic command line arguments for
each job.
\item[\texttt{example\_S3\_H1L1.datafind.sub}]
This is the submit file used to submit datafind jobs to condor. It
includes all the static command line options along with variable command
line options, for each job, that are defined within the main
\texttt{.dag} file.
\item[\texttt{example\_S3\_H1L1.stochastic.sub}]
This is the submit file used to submit stochastic jobs to condor. It
includes all the static command line options along with variable command
line options, for each job, that are defined within the main
\texttt{.dag} file.
\item[\texttt{example\_S3\_H1L1.stopp.sub}]
This is the submit file used to submit stopp jobs to condor. It
includes all the static command line options along with variable command
line options, for each job, that are defined within the main
\texttt{.dag} file.
\item[\texttt{example\_S3\_H1L1.pipeline.log}]
This is the log file that details how the data, from the input segment
list, has been split up into different jobs.
\end{description}

\subsection{Running the DAG}

When the DAG has been created successfully, a message will be displayed
describing what needs to be done inorder to run the analysis pipeline at
a LSC DataGrid Site.

\prog{LSCdataFind} works by querying the datafind server for the
location of the requested data, this requires the user running
LSCdataFind to have a valid grid proxy. Therefore if the DAG includes
any datafind nodes, a valid grid proxy must be available prior to the
job being submitted to the cluster. This is achieved by running the
following commands:

\begin{verbatim}
> unset X509_USER_PROXY
> grid-proxy-init
\end{verbatim}

This will remove any existing proxy and recreate another, requesting the
grid certificates pass phase. The default duration for the proxy to be
valid is 12 hours, if a longer duration is required it can be increased
by appending ``\option{-hours}~\parm{HOURS}'' to the call to
\prog{grid-proxy-init}.

So that LSCdataFind knows what datafind server to query the
\texttt{LSC\_DATAFIND\_SERVER} environment variable must be set to the
address of the datafind server to use. For example, if the pipeline is
being run on the UWM Medusa cluster the relevant datafind server is
shown below, for bash:

\begin{verbatim}
> export LSC_DATAFIND_SERVER=dataserver.phys.uwm.edu
\end{verbatim}

\noindent or for csh:

\begin{verbatim}
> setenv LSC_DATAFIND_SERVER dataserver.phys.uwm.edu
\end{verbatim}

Now that everything is setup, the DAG is ready to be submitted to condor
for execution. This is achieved with the following command.

\begin{verbatim}
> condor_submit_dag example_S3_H1L1.dag
\end{verbatim}

The progress of the DAG can be monitored by studying the DAGman output
file, \texttt{example\_S3\_H1L1.dag.dagman.out}. This contains
information regarding the current state of the search, what jobs have
been completed sucessfully, those that have failed, and those that fail
to run due to unsatisfied dependancies. Once the DAG has completed, if
and jobs have failed, a rescue DAG will be written out. This can be then
submitted to the cluster in the same way as before, the difference is
that this will only attempt to run jobs that previously failed.

NOTE: currently there is a problem with running a large number of
stochastic jobs at any one time. As condor is designed to run jobs that
take over an hour to complete and the average runtime for a stochastic
job is a matter a minutes, running a large number of stocahastic jobs at
the same time will greatly reduce the computational efficiency of a
cluster. Whilst this problem it resolved it is recommended to submit the
DAG with the following command, limiting the total number of jobs to run
to a maximum of 30:

\begin{verbatim}
> condor_submit_dag -maxjobs 30 example_S3_H1L1.dag
\end{verbatim}
