#!/usr/bin/env @PYTHONPROG@
# coding=utf-8
"""
trigger_hipe.in - external-trigger inspiral pipeline driver script

$Id$

This script uses master segment lists to determine a set of segment
lists appropriate to running inspiral_hipe on time around a GRB. At
present, the script only sets up directories and writes appropriate
segment files to those directories.

It uses the same configuration file as the inspiral_hipe script to
determine various parameters and then set up analysis and injection
runs.

"""

__author__ = 'Patrick Brady <patrick@gravity.phys.uwm.edu>'
__date__ = '$Date$'
__version__ = '$Revision$'[11:-2]

##############################################################################
# import standard modules and append the lalapps prefix to the python path
import copy
import os
import sys
import shutil
import ConfigParser
from optparse import *
from glue import segments
from glue import segmentsUtils
from glue import pipeline
import GRButils

##############################################################################
# define a few utility functions that make this job easier

def buildOffSourceSegment ( scienceSegment, grbSegment, dt, ifo ):
  """ Return the segment protracted symmetrically about on-source. """
  scienceSegment = scienceSegment.contract(72)

  nplus = (scienceSegment[1] - grbSegment[1]) // dt 
  nminus = (grbSegment[0] - scienceSegment[0]) // dt

  nsegs = min(nplus, nminus)

  tmpSegment = grbSegment.protract( nsegs * dt + 72 )

  scienceSegment = scienceSegment.protract(72)

  return tmpSegment

def make_external_call(command, show_stdout=False, show_command=False):
  """
  Run a program on the shell and print informative messages on failure.
  """
  if show_command: print command

  stdin, out, err = os.popen3(command)
  pid, status = os.wait()

  if status != 0:
      print >>sys.stderr, "External call failed."
      print >>sys.stderr, "  status: %d" % status
      print >>sys.stderr, "  stdout: %s" % out.read()
      print >>sys.stderr, "  stderr: %s" % err.read()
      print >>sys.stderr, "  command: %s" % command
      sys.exit(status)
  if show_stdout:
      print out.read()
  stdin.close()
  out.close()
  err.close()

# subroutine to plot the segment areas
def plotSegs( seglist, timeOffset, y, col):
  f=None
  # loop over all segments in the list
  for seg in seglist:
    a=ct( seg[0],timeOffset )
    b=ct( seg[1],timeOffset )
    # fill the area
    f=pylab.fill( [a,b,b,a,a], [y,y,y+1, y+1, y], col )
  # return 'pointer' to this filling
  return f

# subroutine to rescale the times
def ct(time, timeOffset):
  return (time-timeOffset)  # /3600.0


def mkdir( directory, overwrite ):
  try:
    os.mkdir(idirectory)
  except OSError:
    if overwrite:
      print "Warning: Overwriting contents in existing directory %s" % directory
    else:
      print "Error: Directory %s already exists!" % directory
      sys.exit(1)


def createInjectionFile( hipe_dir, cp, injrun, segments, source_file, verbose=False):
   """
   Creates an master injection file containing all injections for this run.
   Also reads the file and returns its contents
   """
   from glue.ligolw import ligolw
   from glue.ligolw import utils
   from glue.ligolw import table
   from glue.ligolw import lsctables

   cpinj = copy.deepcopy(cp)

   # get the number of injections to be made
   for opt in ['exttrig-inj-start','exttrig-inj-stop']:
      value = int(cpinj.get(injrun,opt))
      cpinj.remove_option(injrun,opt)
      if 'start' in opt:
        injStart = value
      else: 
        injEnd = value
   seed = injStart
   numberInjections = injEnd-injStart

   # set all the arguments
   argument = []
   for (opt,value) in cpinj.items(injrun):
      argument.append("--%s %s" % (opt, value) )

   # add arguments on times and time-intervals
   interval = segments[1]-segments[0]
   injInterval = interval / float(numberInjections)
   argument.append(" --gps-start-time %d" % segments[0] )
   argument.append(" --gps-end-time %d" % segments[1] )
   argument.append(" --time-interval %f" % injInterval )
   argument.append(" --time-step %f" % injInterval )
   argument.append(" --seed %d" % seed )

   # set output file and exttrig-file
   injFile = "%s/HL-INJECTIONS.xml" % hipe_dir
   argument.append(" --output %s" % injFile )
   argument.append(" --exttrig-file %s" % source_file )

   # execute the command
   arguments = " ".join(argument)
   make_external_call("./lalapps_inspinj %s" % arguments,
      show_stdout=verbose, show_command=verbose)

   # read in the file and the tables
   doc = utils.load_filename( injFile )    
   sims = table.get_table(doc, lsctables.SimInspiralTable.tableName)

   return sims, injInterval, numberInjections


def writeInjectionFile( fileName, sims ):
   """
   Writes a specific part of the sims-table to a file in hipe_dir.
   """
   from glue.ligolw import ligolw
   from glue.ligolw import utils
   from glue.ligolw import table
   from glue.ligolw import lsctables

   # prepare a new XML document
   xmldoc = ligolw.Document()
   xmldoc.appendChild(ligolw.LIGO_LW())
   tbl = lsctables.New(lsctables.SimInspiralTable)
   xmldoc.childNodes[-1].appendChild(tbl)

   # append the entries we want to write
   for sim in sims:
     tbl.append( sim )
   
   # write output file
   utils.write_filename(xmldoc, fileName )



class hipe_run(object):
  """
  This class is intended to represent single run of lalapps_inspiral_hipe.
  """
  def __init__(self, hipe_dir, base_cp, ifos, log_path, source_file, onsource=False, verbose=False):
    self._hipe_dir = hipe_dir
    self._log_path = log_path
    self._cp = copy.copy(base_cp)
    self._ifos = ifos
    self._verbose = verbose

    # create directory here
    if not os.path.isdir(self._hipe_dir):
      os.mkdir(self._hipe_dir)
 
    self._hipe_args = ["--output-segs",
      "--log-path=%s" % log_path, "--config-file=%s",
      "--datafind", "--template-bank", "--inspiral", "--coincidence",
      "--trigbank", "--inspiral-veto", "--second-coinc", "--write-script"]
    
    # determine how many ifos to analyze
    n = len(self._ifos)
    if n < 1 or n > 4:
      raise ValueError, "cannot handle less than one or more than four IFOs"
    number_words = {1: "one", 2: "two", 3: "three", 4: "four"}
    for i in range(n):
      self._hipe_args.append("--%s-ifo" % number_words[i+1])
    
    # set individual ifos to analyze
    for ifo in self._ifos:
      self._cp.set("input", "%s-segments" % ifo.lower(),
        "../%s-selectedsegs.txt" % ifo)
      self._hipe_args.append("--%s-data" % ifo.lower())

    # set the source file for thinca
    cp.set('thinca','exttrig','../../'+source_file)

    # set the on-source segment
    self._cp.set('input','exttrig-segments','../onSourceSeg.txt')
    if onsource:
      self._cp.set('input','exttrig-analyze','on_source')
    else:
      self._cp.set('input','exttrig-analyze','off_source')

      
  
  def set_numslides(self, numslides):
    if numslides == 0: numslides = ""
    self._cp.set('input', 'num-slides', numslides)

  def set_injections(self, cpinj, injrun, numberInjFiles):
    """
    Turn this analysis into an injection run, using the injrun section from
    the config file cpinj.
    """
    cpinj = copy.copy(cpinj)
    
    # set the start and stop seeds from the injection config file
    self._cp.set('pipeline', 'exttrig-inj-start', 1)
    self._cp.set('pipeline', 'exttrig-inj-stop', numberInjFiles)

    # set the rest of the values that should go into section inspinj
    #for (opt,value) in cpinj.items(injrun):
    #  self._cp.set('inspinj',opt,value)

    # set injection segments
    for ifo in self._ifos:
        self._cp.set('input', ifo.lower() + '-segments', "../" + ifo + "-selectedsegs.txt")

    # the start and end time for the injections that are made
    # should be a segment adjacent to the on-source segment. It's
    # convenient to do this here since it needs a calculation.
    # We are assuming that there exists one 180s segment before the trigger
    # on-source interval.
    #self._cp.set('inspinj','gps-start-time',(trigger-120))  # not needed any more
    #self._cp.set('inspinj','gps-end-time',(trigger-120))    # not needed anymore

  def write_dag(self, ini_file_name):
    """
    Create directory and run lalapps_inspiral_hipe to create the DAG.
    """
    os.chdir(self._hipe_dir)
    if not os.path.isdir(self._log_path):  # in case of relative path
      os.mkdir(self._log_path)
    self._cp.write(file(ini_file_name,'w'))
    arguments = " ".join(self._hipe_args)
    make_external_call("../../lalapps_inspiral_hipe %s" % (arguments % ini_file_name),
      show_stdout=self._verbose, show_command=self._verbose)
    os.chdir("../../")
  
  def get_dag_node(self):
    """
    Return a tuple of (job, node), where these refer to this hipe_run's DAG.
    """
    job = pipeline.CondorDAGManJob("%s/config.dag" % self._hipe_dir)
    node = pipeline.CondorDAGNode(job)
    return node
    
##############################################################################
# define usage and command line options and arguments - parse
usage = """usage: %prog ...

Lay down a directory hierarchy appropriate to analyzing the data
around the time of GRB using the inspiral pipeline. It determines an
appropriate amount of data on each side of the reported GRB trigger.

As of now, the code appears to do the right thing.  This code also
uses the inspiral_hipe config file to determine information about
segments and to ensure that appropriate overlaps, etc are being done.  


DIRECTORY HIERARCHY:

The directory hierarchy that a search would have then follows:

searchdir
  GRB<gpstime>
    analysis
    injection001
    injection002
    ....
    injection00n
  .
  .
  .


METADATA FILES:

The script currently writes ....


RELATED TOOLS AND REQUIRED TOOLS:

With a structure like this, a host of other tools can be developed to
make the whole analysis engine work well. Here is a list of things
that we need with a note about its current status:

* inspiral_hipe:  exists and meta-stable
* grb_hipe: exists, but developmental
* grb_summary: exists, but developmental

"""
parser = OptionParser(usage, version="$Id$")

parser.add_option("-v", "--verbose", action="store_true",default=False,\
  help="make things verbose" )
parser.add_option("-G","--g1-segments",action="store",type="string",\
  default=None, metavar=" G1_SEGMENTS", help="G1 input segment to read" )
parser.add_option("-H","--h1-segments",action="store",type="string",\
  default=None, metavar=" H1_SEGMENTS", help="H1 input segment to read" )
parser.add_option("-K","--h2-segments",action="store",type="string",\
  default=None, metavar=" H2_SEGMENTS", help="H2 input segment to read" )
parser.add_option("-L","--l1-segments",action="store",type="string",\
  default=None, metavar=" L1_SEGMENTS", help="L1 input segment to read" )
parser.add_option("-V","--v1-segments",action="store",type="string",\
  default=None, metavar=" V1_SEGMENTS", help="V1 input segment to read" )
parser.add_option("-T","--grb",action="append",type="string",\
    default=None, metavar=" GRB NAME",\
    help="name of the GRB to be analyzed")
parser.add_option("-l","--list",action="store",type="string",\
    default=None, metavar=" GRB LIST",\
    help="path to the file with GRB data stored")
parser.add_option("-a","--onsource-left",action="store",type="int",\
    default=120, metavar=" ONLEFT",\
    help="Specifies the left onsource time window (default: 120)")
parser.add_option("-b","--onsource-right",action="store",type="int",\
    default=60, metavar=" ONRIGHT",\
    help="Specifies the right onsource time window (default:60)")
parser.add_option("-o", "--overwrite-dir", action="store_true",default=False,\
  help="overwrite contents in already existing directories" )
# read in the config file
parser.add_option("-f","--config-file",action="store",type="string",\
  default=None, metavar=" FILE", help="use configuration file FILE" )
parser.add_option("-g","--injection-config",action="store",type="string",\
  default=None, metavar=" FILE", help="use configuration file FILE" )
parser.add_option("-p", "--log-path",action="store",type="string",\
    metavar=" PATH",help="directory to write condor log file")
# Add some plotting capabilities to check things
parser.add_option("-P", "--plot-segments", action="store_true",default=False,\
  help="plot segments for each interval with original segments" )

( opts , args ) = parser.parse_args()


##############################################################################
# create the config parser object and read in the ini file
cp = ConfigParser.ConfigParser()
cp.read(opts.config_file)

##############################################################################
# get the pad and chunk lengths from the values in the ini file
paddata = int(cp.get('data', 'pad-data'))
n = int(cp.get('data', 'segment-length'))
s = int(cp.get('data', 'number-of-segments'))
r = int(cp.get('data', 'sample-rate'))
o = int(cp.get('inspiral', 'segment-overlap'))
length = ( n * s - ( s - 1 ) * o ) / r
overlap = o / r
minsciseg = length + 2 * paddata

##############################################################################
# Read in all the segment lists, filtering for sufficiently long segments
segdict = {}

for ifo in ["G1", "H1", "H2", "L1", "V1"]:
  ifo_segfile = getattr(opts, "%s_segments" % ifo.lower())
  if ifo_segfile is not None:
    tmplist = segmentsUtils.fromsegwizard(open(ifo_segfile))
    segdict[ifo] = segments.segmentlist([s for s in tmplist if abs(s) > minsciseg])
ifolist = segdict.keys()
ifolist.sort()

############################################################################
# set up the Ã¼ber dag for all intervals and all injections

tag = opts.config_file.rstrip(".ini")
uberdag = pipeline.CondorDAG("%s/%s_uberdag.log" % (opts.log_path, tag))
uberdag.set_dag_file("%s_uberdag" % tag)

##############################################################################
# read in the GRB data from the list
listGRB = GRButils.grbTable(opts.list)

if opts.grb[0]=='all':
  usedList = listGRB.rows
else:
  usedList=[]
  for name in opts.grb:

    # search for the given GRB identifier in the list of GRB's
    grb = listGRB.find(name)
    if grb:

      ## add to list
      usedList.append( grb )
    else:
      print "GRB%s couldn't be found in the list. Skipping this GRB." % name

##############################################################################
# loop over the intervals, constructing overlapping segment lists,
# making directories, and writing output to them
for grb in usedList:

  # extract the time of the GRB
  trigger = grb.gpsTime


  ##############################################################################
  # set up the on source segment
  onSourceSegment = segments.segment( trigger - opts.onsource_left, trigger + opts.onsource_right )
  lengthOnsource = opts.onsource_left+opts.onsource_right
  injectionSegment = segments.segment( trigger - minsciseg/2 , 
    trigger + minsciseg/2)

  # name and the directory
  idirectory = "GRB" + str(grb.identifier)
  mkdir( idirectory, opts.overwrite_dir)

  # create the source-file which contains data about the position and time
  # and place it into the corresponding directory
  source_file = idirectory+"/triggerGRB"+grb.identifier+".xml"
  grb.writeExtTrigTable( source_file )


  ##############################################################################
  # set up the segment including the off-source segment

  # first step involves making the segment infinitely large
  offSourceSegment = \
    segments.segment(segments.NegInfinity, segments.PosInfinity)
  
  # for each ifo, construct the maximal segment surrounding the grb, and
  # then use the minimal length segment to actually do the analysis
  for ifo in ifolist:
    try:
      segmentIndex = segdict[ifo].find( trigger )
      trigger_segment = segdict[ifo][segmentIndex]
      tmpOffSourceSegment = \
          buildOffSourceSegment(trigger_segment,onSourceSegment,180,ifo)
      if tmpOffSourceSegment in offSourceSegment:
        offSourceSegment = tmpOffSourceSegment
    except ValueError:
      print "Trigger for GRB %s cannot be found in any segment for %s" % (grb.identifier, ifo)

  # write out the segment list to a segwizard file
  for ifo in ifolist:
    tmpoutfile = idirectory+"/"+ifo+"-selectedsegs.txt"
    segmentsUtils.tosegwizard(file(tmpoutfile,'w'),\
      segments.segmentlist([offSourceSegment]))
    tmpoutfile = idirectory+"/"+ifo+"-injsegs.txt"
    segmentsUtils.tosegwizard(file(tmpoutfile,'w'),\
      segments.segmentlist([injectionSegment]))
  segmentsUtils.tosegwizard(file(idirectory+"/onSourceSeg.txt",'w'),\
      segments.segmentlist([onSourceSegment]))
  
  if opts.verbose:
    print "on-source segment: ", onSourceSegment
    print "off-source segment: ", offSourceSegment
  
   # plot the segment lists
  if opts.plot_segments:
    import pylab
    import numpy
    colorCode={ 'H1':'r', 'H2':'b', 'L1':'g', 'V1':'m', 'G1':'k' }
    hi=len(ifolist)

    pylab.figure()
    pylab.plot([-6,6],[0,hi] ,'w.')
    area={}
    c=0
    for ifo in ifolist:
      area[ifo]=plotSegs( segdict[ifo], trigger, c, colorCode[ifo])
      c+=1
    pylab.axvline(ct(offSourceSegment[0],trigger), color='k', lw=4)
    pylab.axvline(ct(offSourceSegment[1],trigger), color='k', lw=4)
    pylab.axvline(ct(onSourceSegment[0],trigger), color='k', ls='--')
    pylab.axvline(ct(onSourceSegment[1],trigger), color='k', ls='--')
    pylab.xlabel('time [h]')
    pylab.ylabel('IFO')
    a=ct(offSourceSegment[0]-2*minsciseg,trigger)
    b=ct(offSourceSegment[1]+2*minsciseg,trigger)
    pylab.xlim([a, b])
    ax=pylab.axes()
    ticks = numpy.arange( hi )+0.5
    ax.set_yticks(ticks)
    ax.set_yticklabels( ifolist )
    for x in ax.get_xticks():
      pylab.plot([x,x],[0,hi],'k:' )
    for y in range(int(hi)):
      pylab.plot([-6,6],[y,y],'k:' )
    pylab.xlim([a, b])
    pylab.savefig(idirectory+"/segments-"+idirectory+".png")


  # Next thing is to generate the dag for this interval of time.
  # The steps here are:
  #   1. make dir for zero-lag and playground
  #   2. copy in ini file (and modify if needed)
  #   3. generate dag
  #   4. make dir for injections and run inspinj
  #   5. repeat 2 & 3
  #   6. repeat 4 & 5 as needed

  ############################################################################
  # set up the analysis dag for this interval
  #
  # In doing this, we simply copy the configuration file into the
  # sub-directory and then run the dag generation script.
  
  basic_analysis = hipe_run("%s/analysis" % idirectory, cp, ifolist, opts.log_path, source_file, verbose=opts.verbose)
  basic_analysis.write_dag('config.ini')
  uberdag.add_node(basic_analysis.get_dag_node())

  onsource_analysis = hipe_run("%s/onsource" % idirectory, cp, ifolist, opts.log_path, source_file, onsource=True, verbose=opts.verbose)
  onsource_analysis.write_dag('config.ini')
  uberdag.add_node(onsource_analysis.get_dag_node())

  
  ############################################################################
  # create the config parser object and read in the ini file
  if opts.injection_config:
    cpinj = ConfigParser.ConfigParser()
    cpinj.read(opts.injection_config)
    from numpy import asarray
  
    ############################################################################
    # set up the injection dag for this interval
    for injrun in cpinj.sections():
      if opts.verbose: print injrun
      hipe_dir = os.path.join(idirectory, injrun)
      injection_analysis = hipe_run( hipe_dir, cp, ifolist, \
                               opts.log_path, source_file, verbose=opts.verbose)

      # create the master injection file and gets its content
      sims, injInterval, numberInjections = createInjectionFile( hipe_dir, \
                                               cpinj, injrun, offSourceSegment, source_file )
      sims=asarray(sims)

      # split the injections
      safetyInterval = 800.0 # safety time in seconds between two injections
      deltaIndex = int(safetyInterval/injInterval +1)
      for i in range(deltaIndex):
        index = range( i, numberInjections, deltaIndex)
        writeInjectionFile( "%s/HL-INJECTION.%d.xml" % (hipe_dir, i+1),  sims[index] )

      # set the needed parameters
      injection_analysis.set_numslides(0)
      injection_analysis.set_injections(cpinj, injrun, deltaIndex)
      injection_analysis.write_dag('config.ini')
      uberdag.add_node(injection_analysis.get_dag_node())




uberdag.write_sub_files()
uberdag.write_dag()

#print u"""
#If you run the u¼ber-dag, you probably have to tell Condor not to
#complain that your DAG logs are on NFS volumes:
#
#bash users:
#export _CONDOR_DAGMAN_LOG_ON_NFS_IS_ERROR=FALSE
#
#tcsh users:
#setenv _CONDOR_DAGMAN_LOG_ON_NFS_IS_ERROR FALSE
#"""
