#!/usr/bin/env @PYTHONPROG@

import scipy
import sys
import math
import matplotlib
matplotlib.use("Agg")
from pylab import *
from optparse import OptionParser
import os
import numpy
from numpy import *
sys.path.append('@PYTHONLIBDIR@')

parser=OptionParser()
#parser.add_option("-d","--data", dest="data",action="append",help="an input datafile",metavar="insp_out.dat")
parser.add_option("-o","--outsamp",help="location of output file with nested samples", metavar="OUTFILE",default=None,type="string")
parser.add_option("-p","--outpos",help="location of output file of posterior samples",metavar="POSFILE",default=None,type="string")
parser.add_option("-B","--bayesfactor",help="Location of file to store global bayes factor",default=None,type="string")
parser.add_option("-X","--x2iota", dest="xflag", action="store_true", help="If parameter x needs to be converted to iota")
parser.add_option("-N","--Nlive", dest="Nlive", action="store",type="int",help="number of live points for each of the files")
(opts,args)=parser.parse_args()

data=args

if not opts.outsamp and not opts.outpos and not opts.bayesfactor:
	print 'No output specified, nothing to do'
	sys.exit(0)

#path=opts.path
#nfiles=int(datacount)
nfiles=len(data)
xflag=opts.xflag
Nlive=opts.Nlive

def logadd(a,b):
    if(a>b): (a,b)=(b,a)
    return (b+log(1+exp(a-b)))

def getBfile(datname):
    Bfile=datname+'_B.txt'
    print 'Looking for '+Bfile
    if os.access(Bfile,os.R_OK):
        outstat = loadtxt(Bfile)
        return outstat
    else:
        return None

def x2iota(chain):
    chainlen=size(chain)
    iota=[]
    for i in range(0,chainlen):
        if chain[i] < 0:
            new=chain[i]+math.pi
        else:
            new=chain[i]
        iota=iota + [new]

    return (iota)
                                                    
def makelist(path):
    #datalist=[]
    #for i in range(0,N):
    #    datalistitem=path + '/outfile_' + str(i) + '.dat'
    #    datalist += [datalistitem]
     dirlist=os.listdir(path)
     datalist=[]
     for fname in dirlist:
         if 'outfile' in fname and 'B.txt' not in fname:
             fname=path + '/' + fname
             datalist.append(fname)
     return datalist

def loaddata(datalist):
    out = list(map(loadtxt,datalist))
    Bfiles = list(map(getBfile,datalist))
    return out,Bfiles

def prodnoise(B):
    """
    Calculates sum (logZnoise[i] for i!=j) for each j to get logZ to add to each of the input files
    """
    N=len(B)
    totalnoise=[]
    for i in range(0,N):
	tn=0
	for j in range(0,N):
		if i!=j:
			tn+=B[j,2]
        totalnoise.append(tn)
    return totalnoise

def weightsamp(d,Nlive):
    #creates an array of vectors containing weights for every sample in every segment
    total_weight=[]
    for outfile in d:
        N=len(outfile[:,0])
        N_weighted = N - Nlive
        segment_weight=[]
        for i in range(1,N_weighted + 1):
            logw = -(i)/Nlive
            segment_weight.append(logw)
        for i in range(N_weighted + 1,N + 1):
            logw = -N_weighted / Nlive
            segment_weight.append(logw)
        total_weight += segment_weight
    return total_weight

def nest2pos(samps,weights):
    randoms=rand(size(samps,0)) 
    wt=weights+samps[:,-1]
    maxwt=max(wt)
    posidx=find(wt>maxwt+log(randoms))
    pos=samps[posidx,:]
    return pos

#load in seperate data files#
#datalist = makelist(path)
(d,Bfiles) = loaddata(data)
Barray = reduce(lambda x,y: vstack([x,y]), Bfiles)


#Calculate total Bayes factor#
if len(data)>1:
	ZnoiseTotal=sum(Barray[:,2])-log(len(data))
	totalBayes= reduce(logadd,Barray[:,0])
	totalBayes= float(totalBayes) - log(len(data)) #divide by 60 because we used 60 priors
else: 
	totalBayes=Barray[0]
	ZnoiseTotal=Barray[2]
print "Total Bayes Factor= %f" %totalBayes
if opts.bayesfactor is not None:
	bayesfile=open(opts.bayesfactor,'w')
	bayesfile.write('%f' %totalBayes)
	bayesfile.close()

#Scale likelihoods for entire sample#
#Make list of sum(noise evidence), excepting current noise evidence)
if len(data)>1:
	totalnoise = prodnoise(Barray)
else: totalnoise=array([0])
# Add logZnoise for other files to likelihoods for each sample
if not None in Bfiles:
    for (outfile,noise) in zip(d,totalnoise):
        outfile[:,-1]+=noise

#Remapping Parameters#
for outfile in d:
    outfile[:,0]=exp(outfile[:,0])
    outfile[:,4]=exp(outfile[:,4])
    if xflag:
        outfile[:,8]=x2iota(outfile[:,8])

#Posterior Samples
weights=weightsamp(d,Nlive)
d_all = reduce(lambda x,y: vstack([x,y]), d)
pos=nest2pos(d_all,weights)
if opts.outpos is not None:
	posfilename=opts.outpos
	posfile=open(posfilename,'w')
	posfile.write('mchirp \t eta \t time \t phi0 \t dist \t RA \t dec \t psi \t iota \t likelihood \n')
	for row in pos:
    		for i in row:
        		posfile.write('%f\t' %(i))
    		posfile.write('\n')
	posfile.close()

d_idx=argsort(d_all[:,-1])
d_all=d_all[d_idx,:]

#write new output file(s)#
if opts.outsamp is not None:
	outfilename=opts.outsamp
	outfilenew=open(outfilename,'w')
	for row in d_all:
		for i in row:
			outfilenew.write('%f\t' %(i))
        	outfilenew.write('\n')
	outfilenew.close()
	outfileB=open(outfilename+'_B.txt','w')
	# Write out B Zsig Znoise maxL
	print >>outfileB,"%f %f %f %f\n"%(totalBayes, totalBayes+ZnoiseTotal, ZnoiseTotal, pos[-1,-1])
	outfileB.close()

